Perceptron Algorithm Presentation

Hello everyone,

Today, I'll be presenting the perceptron algorithm implemented in my code.

Introduction

The perceptron is a supervised learning algorithm used for binary classification. It adjusts the weights of the input features to minimize prediction errors.

How It Works

Initialize Weights:
The weights are set to zero initially.

Calculate Output:
For each training example, calculate the dot product of the weights and input features, then apply an activation function that returns 1 if the result is positive, otherwise 0.

Update Weights:
If the prediction does not match the expected output, update the weights based on the prediction error using the formula:

weights
+
=
learning rate
×
(
expected output
−
predicted output
)
×
input
weights+=learning rate×(expected output−predicted output)×input
Repeat:
These steps are repeated for a set number of iterations to improve accuracy.

Example Code

Here’s the main part of the code:

python
Copier le code
def perceptron(X, y, learning_rate=0.1, iterations=100):
    weights = np.zeros(X.shape[1])
    for _ in range(iterations):
        for i in range(len(X)):
            z = np.dot(weights, X[i])
            y_pred = 1 if z >= 0 else 0
            weights += learning_rate * (y[i] - y_pred) * X[i]
    return weights
Visualization

To visualize the linear separator learned by    the perceptron:

python
Copier le code
plt.scatter(X_train[:, 1], X_train[:, 2], c=y_train, cmap='bwr')
x_vals = np.array([min(X_train[:, 1]), max(X_train[:, 1])])
y_vals = -(weights[1] * x_vals + weights[0]) / weights[2]
plt.plot(x_vals, y_vals, color='black')
plt.xlabel('Sepal Length')
plt.ylabel('Petal Length')
plt.title('Perceptron Classification')
plt.show()
Conclusion

The perceptron is a simple and effective model for linearly separable problems, offering a good introduction to machine learning and neural networks.

Thank you for your attention!